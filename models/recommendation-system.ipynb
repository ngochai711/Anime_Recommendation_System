{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![CF](https://dataconomy.com/wp-content/uploads/2015/03/Beginners-Guide-Recommender-Systems-Collaborative-Filtering-620x340.jpg)\n\n## **Collaborative Filtering**\n+ **predicting** what **users** will **like** based on their **similarity to other users.**\n+ **Advantages:** capable of accurately recommending complex items such as movies without requiring an “understanding” of the item itself. \n+ many  have been used in measuring (**user similarity** or **item similarity**) in **recommender systems.** \n+ **Task 1**: finding similar animes\n+ **Task 2**: finding similar users\n+ **Task 3**: Recommending Animes for a random user","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = '/kaggle/input/anime-recommendation-database-2020'\n!ls {INPUT_DIR}","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-12-29T03:20:32.767540Z","iopub.execute_input":"2022-12-29T03:20:32.767955Z","iopub.status.idle":"2022-12-29T03:20:33.084212Z","shell.execute_reply.started":"2022-12-29T03:20:32.767840Z","shell.execute_reply":"2022-12-29T03:20:33.082683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nrating_df = pd.read_csv(INPUT_DIR + '/animelist.csv', \n                        low_memory=False, \n                        usecols=[\"user_id\", \"anime_id\", \"rating\"]\n                        #, nrows=90000000\n                        )\nrating_df.head(4)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:20:33.087152Z","iopub.execute_input":"2022-12-29T03:20:33.087885Z","iopub.status.idle":"2022-12-29T03:21:32.467926Z","shell.execute_reply.started":"2022-12-29T03:20:33.087821Z","shell.execute_reply":"2022-12-29T03:21:32.466971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# User should rate atleast 400 animies\nn_ratings = rating_df['user_id'].value_counts()\nrating_df = rating_df[rating_df['user_id'].isin(n_ratings[n_ratings >= 400].index)].copy()\nlen(rating_df)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:21:32.469084Z","iopub.execute_input":"2022-12-29T03:21:32.469311Z","iopub.status.idle":"2022-12-29T03:21:36.278125Z","shell.execute_reply.started":"2022-12-29T03:21:32.469286Z","shell.execute_reply":"2022-12-29T03:21:36.277615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Scaling BTW (0 , 1.0)\nmin_rating = min(rating_df['rating'])\nmax_rating = max(rating_df['rating'])\nrating_df['rating'] = rating_df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating)).values.astype(np.float64)\n\nAvgRating = np.mean(rating_df['rating'])\nprint('Avg', AvgRating)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:21:36.279503Z","iopub.execute_input":"2022-12-29T03:21:36.279776Z","iopub.status.idle":"2022-12-29T03:22:09.882062Z","shell.execute_reply.started":"2022-12-29T03:21:36.279752Z","shell.execute_reply":"2022-12-29T03:22:09.880844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing Duplicated Rows\nduplicates = rating_df.duplicated()\n\nif duplicates.sum() > 0:\n    print('> {} duplicates'.format(duplicates.sum()))\n    rating_df = rating_df[~duplicates]\n\nprint('> {} duplicates'.format(rating_df.duplicated().sum()))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:22:09.883426Z","iopub.execute_input":"2022-12-29T03:22:09.883643Z","iopub.status.idle":"2022-12-29T03:22:58.301500Z","shell.execute_reply.started":"2022-12-29T03:22:09.883617Z","shell.execute_reply":"2022-12-29T03:22:58.300964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://content.codecademy.com/programs/code-foundations-path/ds-survey/utilitymatrix.gif)","metadata":{}},{"cell_type":"code","source":"g = rating_df.groupby('user_id')['rating'].count()\ntop_users = g.dropna().sort_values(ascending=False)[:20]\ntop_r = rating_df.join(top_users, rsuffix='_r', how='inner', on='user_id')\n\ng = rating_df.groupby('anime_id')['rating'].count()\ntop_animes = g.dropna().sort_values(ascending=False)[:20]\ntop_r = top_r.join(top_animes, rsuffix='_r', how='inner', on='anime_id')\n\npd.crosstab(top_r.user_id, top_r.anime_id, top_r.rating, aggfunc=np.sum)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-12-29T03:22:58.302543Z","iopub.execute_input":"2022-12-29T03:22:58.302843Z","iopub.status.idle":"2022-12-29T03:23:03.577086Z","shell.execute_reply.started":"2022-12-29T03:22:58.302815Z","shell.execute_reply":"2022-12-29T03:23:03.576478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Data Preprocessing**","metadata":{}},{"cell_type":"code","source":"# Encoding categorical data\nuser_ids = rating_df[\"user_id\"].unique().tolist()\nuser2user_encoded = {x: i for i, x in enumerate(user_ids)}\nuser_encoded2user = {i: x for i, x in enumerate(user_ids)}\nrating_df[\"user\"] = rating_df[\"user_id\"].map(user2user_encoded)\nn_users = len(user2user_encoded)\n\nanime_ids = rating_df[\"anime_id\"].unique().tolist()\nanime2anime_encoded = {x: i for i, x in enumerate(anime_ids)}\nanime_encoded2anime = {i: x for i, x in enumerate(anime_ids)}\nrating_df[\"anime\"] = rating_df[\"anime_id\"].map(anime2anime_encoded)\nn_animes = len(anime2anime_encoded)\n\nprint(\"Num of users: {}, Num of animes: {}\".format(n_users, n_animes))\nprint(\"Min rating: {}, Max rating: {}\".format(min(rating_df['rating']), max(rating_df['rating'])))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:23:03.578426Z","iopub.execute_input":"2022-12-29T03:23:03.578835Z","iopub.status.idle":"2022-12-29T03:23:18.691328Z","shell.execute_reply.started":"2022-12-29T03:23:03.578799Z","shell.execute_reply":"2022-12-29T03:23:18.690503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle\nrating_df = rating_df.sample(frac=1, random_state=73)\n\nX = rating_df[['user', 'anime']].values\ny = rating_df[\"rating\"]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:23:18.692474Z","iopub.execute_input":"2022-12-29T03:23:18.692734Z","iopub.status.idle":"2022-12-29T03:23:34.768054Z","shell.execute_reply.started":"2022-12-29T03:23:18.692704Z","shell.execute_reply":"2022-12-29T03:23:34.766466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split\ntest_set_size = 10000 #10k for test set\ntrain_indices = rating_df.shape[0] - test_set_size \n\nX_train, X_test, y_train, y_test = (\n    X[:train_indices],\n    X[train_indices:],\n    y[:train_indices],\n    y[train_indices:],\n)\n\nprint('> Train set ratings: {}'.format(len(y_train)))\nprint('> Test set ratings: {}'.format(len(y_test)))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:23:34.769931Z","iopub.execute_input":"2022-12-29T03:23:34.770259Z","iopub.status.idle":"2022-12-29T03:23:34.779567Z","shell.execute_reply.started":"2022-12-29T03:23:34.770218Z","shell.execute_reply":"2022-12-29T03:23:34.778153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_array = [X_train[:, 0], X_train[:, 1]]\nX_test_array = [X_test[:, 0], X_test[:, 1]]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:23:34.782432Z","iopub.execute_input":"2022-12-29T03:23:34.782735Z","iopub.status.idle":"2022-12-29T03:23:34.792879Z","shell.execute_reply.started":"2022-12-29T03:23:34.782709Z","shell.execute_reply":"2022-12-29T03:23:34.791971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Accelerator check\nimport tensorflow as tf\n\nTPU_INIT = True\n\nif TPU_INIT:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    !nvidia-smi\n    \nprint(tf.__version__)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-12-29T03:39:08.022791Z","iopub.execute_input":"2022-12-29T03:39:08.025795Z","iopub.status.idle":"2022-12-29T03:39:08.058707Z","shell.execute_reply.started":"2022-12-29T03:39:08.025686Z","shell.execute_reply":"2022-12-29T03:39:08.057660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Model Building**","metadata":{}},{"cell_type":"code","source":"import tensorflow.keras\nfrom tensorflow.keras import layers \nimport tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:39:20.154191Z","iopub.execute_input":"2022-12-29T03:39:20.154547Z","iopub.status.idle":"2022-12-29T03:39:20.162263Z","shell.execute_reply.started":"2022-12-29T03:39:20.154508Z","shell.execute_reply":"2022-12-29T03:39:20.160720Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Embedding layers\nfrom tensorflow.keras.layers import Add, Activation, Lambda, BatchNormalization, Concatenate, Dropout, Input, Embedding, Dot, Reshape, Dense, Flatten\n\ndef RecommenderNet():\n    embedding_size = 128\n    \n    user = Input(name = 'user', shape = [1])\n    user_embedding = Embedding(name = 'user_embedding',\n                       input_dim = n_users, \n                       output_dim = embedding_size)(user)\n    \n    anime = Input(name = 'anime', shape = [1])\n    anime_embedding = Embedding(name = 'anime_embedding',\n                       input_dim = n_animes, \n                       output_dim = embedding_size)(anime)\n    \n    #x = Concatenate()([user_embedding, anime_embedding])\n    x = Dot(name = 'dot_product', normalize = True, axes = 2)([user_embedding, anime_embedding])\n    x = Flatten()(x)\n        \n    x = Dense(1, kernel_initializer='he_normal')(x)\n    x = BatchNormalization()(x)\n    x = Activation(\"sigmoid\")(x)\n    \n    model = Model(inputs=[user, anime], outputs=x)\n    model.compile(loss='binary_crossentropy', metrics=[\"mae\", \"mse\"], optimizer='Adam')\n    \n    return model\n\nif TPU_INIT:    \n    with tpu_strategy.scope():\n        model = RecommenderNet()\nelse:\n    model = RecommenderNet()\n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:39:26.124487Z","iopub.execute_input":"2022-12-29T03:39:26.125185Z","iopub.status.idle":"2022-12-29T03:39:26.908701Z","shell.execute_reply.started":"2022-12-29T03:39:26.125136Z","shell.execute_reply":"2022-12-29T03:39:26.907445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callbacks\nfrom tensorflow.keras.callbacks import Callback, ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping, ReduceLROnPlateau\n\nstart_lr = 0.00001\nmin_lr = 0.00001\nmax_lr = 0.00005\nbatch_size = 10000\n\nif TPU_INIT:\n    max_lr = max_lr * tpu_strategy.num_replicas_in_sync\n    batch_size = batch_size * tpu_strategy.num_replicas_in_sync\n    \nrampup_epochs = 5\nsustain_epochs = 0\nexp_decay = .8\n\ndef lrfn(epoch):\n    if epoch < rampup_epochs:\n        return (max_lr - start_lr)/rampup_epochs * epoch + start_lr\n    elif epoch < rampup_epochs + sustain_epochs:\n        return max_lr\n    else:\n        return (max_lr - min_lr) * exp_decay**(epoch-rampup_epochs-sustain_epochs) + min_lr\n\n\nlr_callback = LearningRateScheduler(lambda epoch: lrfn(epoch), verbose=0)\n\ncheckpoint_filepath = './weights.h5'\n\nmodel_checkpoints = ModelCheckpoint(filepath=checkpoint_filepath,\n                                        save_weights_only=True,\n                                        monitor='val_loss',\n                                        mode='min',\n                                        save_best_only=True)\n\nearly_stopping = EarlyStopping(patience = 3, monitor='val_loss', \n                               mode='min', restore_best_weights=True)\n\nmy_callbacks = [\n    model_checkpoints,\n    lr_callback,\n    early_stopping,   \n]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:39:33.497168Z","iopub.execute_input":"2022-12-29T03:39:33.497557Z","iopub.status.idle":"2022-12-29T03:39:33.511083Z","shell.execute_reply.started":"2022-12-29T03:39:33.497517Z","shell.execute_reply":"2022-12-29T03:39:33.509750Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model training\nhistory = model.fit(\n    x=X_train_array,\n    y=y_train,\n    batch_size=batch_size,\n    epochs=20,\n    verbose=1,\n    validation_data=(X_test_array, y_test),\n    callbacks=my_callbacks\n)\n\nmodel.load_weights(checkpoint_filepath)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:39:37.820937Z","iopub.execute_input":"2022-12-29T03:39:37.821530Z","iopub.status.idle":"2022-12-29T03:44:42.500307Z","shell.execute_reply.started":"2022-12-29T03:39:37.821485Z","shell.execute_reply":"2022-12-29T03:44:42.498682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Training results\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history[\"loss\"][0:-2])\nplt.plot(history.history[\"val_loss\"][0:-2])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"epoch\")\nplt.legend([\"train\", \"test\"], loc=\"upper left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:02.094903Z","iopub.execute_input":"2022-12-29T03:52:02.096821Z","iopub.status.idle":"2022-12-29T03:52:02.382974Z","shell.execute_reply.started":"2022-12-29T03:52:02.096716Z","shell.execute_reply":"2022-12-29T03:52:02.381358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Extracting weights from model**","metadata":{}},{"cell_type":"code","source":"def extract_weights(name, model):\n    weight_layer = model.get_layer(name)\n    weights = weight_layer.get_weights()[0]\n    weights = weights / np.linalg.norm(weights, axis = 1).reshape((-1, 1))\n    return weights\n\nanime_weights = extract_weights('anime_embedding', model)\nuser_weights = extract_weights('user_embedding', model)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:02.385542Z","iopub.execute_input":"2022-12-29T03:52:02.386427Z","iopub.status.idle":"2022-12-29T03:52:02.589887Z","shell.execute_reply.started":"2022-12-29T03:52:02.386377Z","shell.execute_reply":"2022-12-29T03:52:02.588339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **anime meta data**","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(INPUT_DIR + '/anime.csv', low_memory=True)\ndf = df.replace(\"Unknown\", np.nan)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:02.591813Z","iopub.execute_input":"2022-12-29T03:52:02.592093Z","iopub.status.idle":"2022-12-29T03:52:02.896450Z","shell.execute_reply.started":"2022-12-29T03:52:02.592061Z","shell.execute_reply":"2022-12-29T03:52:02.894545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fixing Names\ndef getAnimeName(anime_id):\n    try:\n        name = df[df.anime_id == anime_id].eng_version.values[0]\n        if name is np.nan:\n            name = df[df.anime_id == anime_id].Name.values[0]\n    except:\n        print('error')\n    \n    return name\n\ndf['anime_id'] = df['MAL_ID']\ndf[\"eng_version\"] = df['English name']\ndf['eng_version'] = df.anime_id.apply(lambda x: getAnimeName(x))\n\ndf.sort_values(by=['Score'], \n               inplace=True,\n               ascending=False, \n               kind='quicksort',\n               na_position='last')\n\ndf = df[[\"anime_id\", \"eng_version\", \n         \"Score\", \"Genres\", \"Episodes\", \n         \"Type\", \"Premiered\", \"Members\"]]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:02.899784Z","iopub.execute_input":"2022-12-29T03:52:02.900166Z","iopub.status.idle":"2022-12-29T03:52:12.931402Z","shell.execute_reply.started":"2022-12-29T03:52:02.900122Z","shell.execute_reply":"2022-12-29T03:52:12.930641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getAnimeFrame(anime):\n    if isinstance(anime, int):\n        return df[df.anime_id == anime]\n    if isinstance(anime, str):\n        return df[df.eng_version == anime]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:12.932580Z","iopub.execute_input":"2022-12-29T03:52:12.933530Z","iopub.status.idle":"2022-12-29T03:52:12.939583Z","shell.execute_reply.started":"2022-12-29T03:52:12.933495Z","shell.execute_reply":"2022-12-29T03:52:12.938088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **sypnopsis data**","metadata":{}},{"cell_type":"code","source":"cols = [\"MAL_ID\", \"Name\", \"Genres\", \"sypnopsis\"]\nsypnopsis_df = pd.read_csv(INPUT_DIR + '/anime_with_synopsis.csv', usecols=cols)\n\ndef getSypnopsis(anime):\n    if isinstance(anime, int):\n        return sypnopsis_df[sypnopsis_df.MAL_ID == anime].sypnopsis.values[0]\n    if isinstance(anime, str):\n        return sypnopsis_df[sypnopsis_df.Name == anime].sypnopsis.values[0]","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:12.940868Z","iopub.execute_input":"2022-12-29T03:52:12.942668Z","iopub.status.idle":"2022-12-29T03:52:13.183922Z","shell.execute_reply.started":"2022-12-29T03:52:12.942589Z","shell.execute_reply":"2022-12-29T03:52:13.182795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 1**: Finding Similar Animes (Item Based Recommendation)","metadata":{}},{"cell_type":"code","source":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_animes(name, n=10, return_dist=False, neg=False):\n    try:\n        index = getAnimeFrame(name).anime_id.values[0]\n        encoded_index = anime2anime_encoded.get(index)\n        weights = anime_weights\n        \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1            \n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('animes closest to {}'.format(name))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n\n        SimilarityArr = []\n\n        for close in closest:\n            decoded_id = anime_encoded2anime.get(close)\n            sypnopsis = getSypnopsis(decoded_id)\n            anime_frame = getAnimeFrame(decoded_id)\n            \n            anime_name = anime_frame.eng_version.values[0]\n            genre = anime_frame.Genders.values[0]\n            similarity = dists[close]\n            SimilarityArr.append({\"anime_id\": decoded_id, \"name\": anime_name,\n                                  \"similarity\": similarity,\"genre\": genre,\n                                  'sypnopsis': sypnopsis})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", ascending=False)\n        return Frame[Frame.anime_id != index].drop(['anime_id'], axis=1)\n\n    except:\n        print('{}!, Not Found in Anime list'.format(name))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:13.185131Z","iopub.execute_input":"2022-12-29T03:52:13.186257Z","iopub.status.idle":"2022-12-29T03:52:13.197779Z","shell.execute_reply.started":"2022-12-29T03:52:13.186215Z","shell.execute_reply":"2022-12-29T03:52:13.196488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **these animes are my fav**","metadata":{}},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/1f/cb/2a/1fcb2af4376fe78b6d82197bd1fdbff6.gif)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Elfen Lied', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:13.200166Z","iopub.execute_input":"2022-12-29T03:52:13.200731Z","iopub.status.idle":"2022-12-29T03:52:13.230755Z","shell.execute_reply.started":"2022-12-29T03:52:13.200691Z","shell.execute_reply":"2022-12-29T03:52:13.229769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://64.media.tumblr.com/1b942774dc6d4240cfbb3da22d99a681/tumblr_phsucvmeDT1sivxmj_500.gifv)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Your Name.', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:13.232103Z","iopub.execute_input":"2022-12-29T03:52:13.233396Z","iopub.status.idle":"2022-12-29T03:52:13.253252Z","shell.execute_reply.started":"2022-12-29T03:52:13.233347Z","shell.execute_reply":"2022-12-29T03:52:13.251909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://i.pinimg.com/originals/26/fd/49/26fd49fa54b204fbaf6301efefd53ae2.gif)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('GATE', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:13.258773Z","iopub.execute_input":"2022-12-29T03:52:13.259529Z","iopub.status.idle":"2022-12-29T03:52:13.278453Z","shell.execute_reply.started":"2022-12-29T03:52:13.259484Z","shell.execute_reply":"2022-12-29T03:52:13.277067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://steamuserimages-a.akamaihd.net/ugc/993512070845192516/C18040A95DB14DD58438DDDEBF721BA8ABAD0E84/)","metadata":{}},{"cell_type":"code","source":"find_similar_animes('Black Clover', n=5, neg=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T03:52:13.279551Z","iopub.execute_input":"2022-12-29T03:52:13.279788Z","iopub.status.idle":"2022-12-29T03:52:13.292993Z","shell.execute_reply.started":"2022-12-29T03:52:13.279758Z","shell.execute_reply":"2022-12-29T03:52:13.292398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 2**: Finding Similar Users (User Based Recommendation)","metadata":{}},{"cell_type":"code","source":"print('> picking up random user')\n\nratings_per_user = rating_df.groupby('user_id').size()\nrandom_user = ratings_per_user[ratings_per_user < 500].sample(1, random_state=None).index[0]\nprint('> user_id:', random_user)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:48.916399Z","iopub.execute_input":"2022-12-29T04:08:48.917080Z","iopub.status.idle":"2022-12-29T04:08:51.338476Z","shell.execute_reply.started":"2022-12-29T04:08:48.917038Z","shell.execute_reply":"2022-12-29T04:08:51.337308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pd.reset_option('all')\npd.set_option(\"max_colwidth\", None)\n\ndef find_similar_users(item_input, n=10,return_dist=False, neg=False):\n    try:\n        index = item_input\n        encoded_index = user2user_encoded.get(index)\n        weights = user_weights\n    \n        dists = np.dot(weights, weights[encoded_index])\n        sorted_dists = np.argsort(dists)\n        \n        n = n + 1\n        \n        if neg:\n            closest = sorted_dists[:n]\n        else:\n            closest = sorted_dists[-n:]\n\n        print('> users similar to #{}'.format(item_input))\n\n        if return_dist:\n            return dists, closest\n        \n        rindex = df\n        SimilarityArr = []\n        \n        for close in closest:\n            similarity = dists[close]\n\n            if isinstance(item_input, int):\n                decoded_id = user_encoded2user.get(close)\n                SimilarityArr.append({\"similar_users\": decoded_id, \n                                      \"similarity\": similarity})\n\n        Frame = pd.DataFrame(SimilarityArr).sort_values(by=\"similarity\", \n                                                        ascending=False)\n        \n        return Frame\n    \n    except:\n        print('{}!, Not Found in User list'.format(name))","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.340536Z","iopub.execute_input":"2022-12-29T04:08:51.340986Z","iopub.status.idle":"2022-12-29T04:08:51.351255Z","shell.execute_reply.started":"2022-12-29T04:08:51.340942Z","shell.execute_reply":"2022-12-29T04:08:51.349483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#random_user =88895\nsimilar_users = find_similar_users(int(random_user), \n                                   n=5, \n                                   neg=False)\n\nsimilar_users = similar_users[similar_users.similarity > 0.4]\nsimilar_users = similar_users[similar_users.similar_users != random_user]\nsimilar_users.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.353883Z","iopub.execute_input":"2022-12-29T04:08:51.354278Z","iopub.status.idle":"2022-12-29T04:08:51.388374Z","shell.execute_reply.started":"2022-12-29T04:08:51.354228Z","shell.execute_reply":"2022-12-29T04:08:51.387748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **User preferences**","metadata":{}},{"cell_type":"code","source":"from wordcloud import WordCloud\nfrom collections import defaultdict\nimport matplotlib.pyplot as plt\n\ndef showWordCloud(all_genres):\n    genres_cloud = WordCloud(width=700, height=400, \n                             background_color='white', \n                             colormap='gnuplot').generate_from_frequencies(all_genres)\n    \n    plt.figure(figsize=(10,8)) \n    plt.imshow(genres_cloud, interpolation='bilinear')\n    plt.axis('off')\n    plt.show()\n\ndef getFavGenre(frame, plot=False):\n        frame.dropna(inplace=False)\n        all_genres = defaultdict(int)\n        \n        genres_list = []\n        for genres in frame['Genres']:\n            if isinstance(genres, str):\n                for genre in genres.split(','):\n                    genres_list.append(genre)\n                    all_genres[genre.strip()] += 1    \n        if plot:\n            showWordCloud(all_genres)\n        \n        return genres_list\n\n    \ndef get_user_preferences(user_id, plot=False, verbose=0):\n    animes_watched_by_user = rating_df[rating_df.user_id==user_id]\n    user_rating_percentile = np.percentile(animes_watched_by_user.rating, 75)\n    animes_watched_by_user = animes_watched_by_user[animes_watched_by_user.rating >= user_rating_percentile]\n    top_animes_user = (\n        animes_watched_by_user.sort_values(by=\"rating\", ascending=False)#.head(10)\n        .anime_id.values\n    )\n    \n    anime_df_rows = df[df[\"anime_id\"].isin(top_animes_user)]\n    anime_df_rows = anime_df_rows[[\"eng_version\", \"Genres\"]]\n    \n    if verbose != 0:\n        print(\"> User #{} has rated {} movies (avg. rating = {:.1f})\".format(\n          user_id, len(animes_watched_by_user),\n          animes_watched_by_user['rating'].mean(),\n        ))\n    \n        print('> preferred genres')\n    \n    if plot:\n        getFavGenre(anime_df_rows, plot)\n        \n    return anime_df_rows#.eng_version.values","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.390230Z","iopub.execute_input":"2022-12-29T04:08:51.390611Z","iopub.status.idle":"2022-12-29T04:08:51.402275Z","shell.execute_reply.started":"2022-12-29T04:08:51.390579Z","shell.execute_reply":"2022-12-29T04:08:51.401635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_pref = get_user_preferences(random_user, plot=True, verbose=1)\nprint('> animes highly rated by this user')\n\npd.DataFrame(user_pref).head(5)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.403510Z","iopub.execute_input":"2022-12-29T04:08:51.403826Z","iopub.status.idle":"2022-12-29T04:08:51.935084Z","shell.execute_reply.started":"2022-12-29T04:08:51.403798Z","shell.execute_reply":"2022-12-29T04:08:51.934163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Task 3**: **Recommending** animes for a user","metadata":{}},{"cell_type":"code","source":"def get_recommended_animes(similar_users, n=10):\n    recommended_animes = []\n    anime_list = []\n    \n    for user_id in similar_users.similar_users.values:\n        pref_list = get_user_preferences(int(user_id), verbose=0)\n        pref_list = pref_list[~ pref_list.eng_version.isin(user_pref.eng_version.values)]\n        anime_list.append(pref_list.eng_version.values)\n        \n    anime_list = pd.DataFrame(anime_list)\n    sorted_list = pd.DataFrame(pd.Series(anime_list.values.ravel()).value_counts()).head(n)\n    \n    for i, anime_name in enumerate(sorted_list.index):        \n        n_user_pref = sorted_list[sorted_list.index == anime_name].values[0][0]\n        if isinstance(anime_name, str):\n            try:\n                frame = getAnimeFrame(anime_name)\n                anime_id = frame.anime_id.values[0]\n                genre = frame.Genres.values[0]\n                sypnopsis = getSypnopsis(int(anime_id))\n                recommended_animes.append({#\"anime_id\": anime_id ,\n                                            \"n\": n_user_pref,\n                                            \"anime_name\": anime_name, \n                                            \"Genres\": genre, \n                                            \"sypnopsis\": sypnopsis})\n            except:\n                pass\n    \n    return pd.DataFrame(recommended_animes)","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.936494Z","iopub.execute_input":"2022-12-29T04:08:51.936831Z","iopub.status.idle":"2022-12-29T04:08:51.946773Z","shell.execute_reply.started":"2022-12-29T04:08:51.936800Z","shell.execute_reply":"2022-12-29T04:08:51.944858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"recommended_animes = get_recommended_animes(similar_users, n=10)\ngetFavGenre(recommended_animes, plot=True)\n\nprint('\\n> Top recommendations for user: {}'.format(random_user))\nrecommended_animes","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:51.948349Z","iopub.execute_input":"2022-12-29T04:08:51.949737Z","iopub.status.idle":"2022-12-29T04:08:52.731676Z","shell.execute_reply.started":"2022-12-29T04:08:51.949667Z","shell.execute_reply":"2022-12-29T04:08:52.730529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Ranking based Recommendation**","metadata":{}},{"cell_type":"code","source":"print(\"Showing recommendations for user: {}\".format(random_user))\nprint(\"===\" * 25)\n\nanimes_watched_by_user = rating_df[rating_df.user_id==random_user]\nanime_not_watched_df = df[\n    ~df[\"anime_id\"].isin(animes_watched_by_user.anime_id.values)\n]\n\nanime_not_watched = list(\n    set(anime_not_watched_df['anime_id']).intersection(set(anime2anime_encoded.keys()))\n)\n\nanime_not_watched = [[anime2anime_encoded.get(x)] for x in anime_not_watched]\n\nuser_encoder = user2user_encoded.get(random_user)\n\nuser_anime_array = np.hstack(\n    ([[user_encoder]] * len(anime_not_watched), anime_not_watched)\n)\n\nuser_anime_array = [user_anime_array[:, 0], user_anime_array[:, 1]]\nratings = model.predict(user_anime_array).flatten()\n\ntop_ratings_indices = (-ratings).argsort()[:10]\n\nrecommended_anime_ids = [\n    anime_encoded2anime.get(anime_not_watched[x][0]) for x in top_ratings_indices\n]\n\nResults = []\ntop_rated_ids = []\n\nfor index, anime_id in enumerate(anime_not_watched):\n    rating = ratings[index]\n    id_ = anime_encoded2anime.get(anime_id[0])\n    \n    if id_ in recommended_anime_ids:\n        top_rated_ids.append(id_)\n        try:\n            condition = (df.anime_id == id_)\n            name = df[condition]['eng_version'].values[0]\n            genre = df[condition].Genres.values[0]\n            score = df[condition].Score.values[0]\n            sypnopsis = getSypnopsis(int(id_))\n        except:\n            continue\n            \n        Results.append({#\"anime_id\": id_, \n                        \"name\": name, \n                        \"pred_rating\": rating,\n                        \"genre\": genre, \n                        'sypnopsis': sypnopsis})\n\nprint(\"---\" * 25)\nprint(\"> Top 10 anime recommendations\")\nprint(\"---\" * 25)\n\n\nResults = pd.DataFrame(Results).sort_values(by='pred_rating', ascending=False)\nResults","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:52.733252Z","iopub.execute_input":"2022-12-29T04:08:52.733582Z","iopub.status.idle":"2022-12-29T04:08:55.621707Z","shell.execute_reply.started":"2022-12-29T04:08:52.733552Z","shell.execute_reply":"2022-12-29T04:08:55.620474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model.save('anime_model.h5')\n\n#from IPython.display import FileLink\n#FileLink(r'./anime_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-12-29T04:08:55.623098Z","iopub.execute_input":"2022-12-29T04:08:55.623381Z","iopub.status.idle":"2022-12-29T04:08:55.626901Z","shell.execute_reply.started":"2022-12-29T04:08:55.623340Z","shell.execute_reply":"2022-12-29T04:08:55.626194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}